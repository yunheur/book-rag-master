{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cJy1t37GsyL9",
   "metadata": {
    "id": "cJy1t37GsyL9"
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b57306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U3aOf1kttmdQ",
   "metadata": {
    "id": "U3aOf1kttmdQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u9eVNXBIUTsb",
   "metadata": {
    "id": "u9eVNXBIUTsb"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = (\n",
    "    \"/content/drive/MyDrive/langchain-tutorial/Ch04. Advanced Rag/Data/투자설명서.pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap = 100)\n",
    "\n",
    "docs = loader.load_and_split(doc_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wtwTgjcwQp1o",
   "metadata": {
    "id": "wtwTgjcwQp1o"
   },
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 데이터를 임베딩으로 변환\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p3PNlgs44qHB",
   "metadata": {
    "id": "p3PNlgs44qHB"
   },
   "outputs": [],
   "source": [
    "# FAISS 라이브러리 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터스토어 생성\n",
    "faiss_store = FAISS.from_documents(docs, embedding)\n",
    "# FAISS 벡터스토어 저장\n",
    "persist_directory = \"/content/DB\"\n",
    "faiss_store.save_local(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urRxIxM3sUcS",
   "metadata": {
    "id": "urRxIxM3sUcS"
   },
   "outputs": [],
   "source": [
    "# 저장한 FAISS DB 불러오기\n",
    "vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QO7i-mOHQ4vx",
   "metadata": {
    "id": "QO7i-mOHQ4vx"
   },
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NkIsOHAOQ7AY",
   "metadata": {
    "id": "NkIsOHAOQ7AY"
   },
   "outputs": [],
   "source": [
    "# ms-marco-MiniLM-L-12-v2 모델 다운로드\n",
    "crossencoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sLBgdtjK6UUX",
   "metadata": {
    "id": "sLBgdtjK6UUX"
   },
   "outputs": [],
   "source": [
    "class Retriever_with_cross_encoder(BaseRetriever):\n",
    "    vectorstore: Any = Field(description=\"초기 검색을 위한 벡터 저장소\")\n",
    "    crossencoder: Any = Field(description=\"재순위화를 위한 크로스 인코더 모델\")\n",
    "    k: int = Field(default=5, description=\"초기에 검색할 문서 수\")\n",
    "    rerank_top_k: int = Field(default=2, description=\"재순위화 후 최종적으로 반환할 문서 수\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # 초기 검색\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
    "\n",
    "        # 인코더용 쌍 준비\n",
    "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
    "\n",
    "        # 인코더 점수 획득\n",
    "        scores = self.crossencoder.predict(pairs)\n",
    "\n",
    "        # 점수별 문서 정렬\n",
    "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 상위 재순위화 문서 반환\n",
    "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GQgtEgOLRtwJ",
   "metadata": {
    "id": "GQgtEgOLRtwJ"
   },
   "outputs": [],
   "source": [
    "# 크로스인코더 기반 리트리버 인스턴스 생성\n",
    "cross_encoder_retriever = Retriever_with_cross_encoder(\n",
    "    vectorstore=vectordb,\n",
    "    crossencoder=crossencoder,\n",
    "    k=4,  # 초기 밀집검색으로 반환할 문서 수를 설정\n",
    "    rerank_top_k=2  # 리랭킹을 통해 최종적으로 반환할 문서 수를 설정\n",
    ")\n",
    "\n",
    "# 답변용 LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XRsXe5Q47eft",
   "metadata": {
    "id": "XRsXe5Q47eft"
   },
   "outputs": [],
   "source": [
    "# RetrievalQA 체인 인스턴스 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=cross_encoder_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GtjlHUxKIOm4",
   "metadata": {
    "id": "GtjlHUxKIOm4"
   },
   "outputs": [],
   "source": [
    "query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {result['result']}\")\n",
    "print(\"\\n답변 근거 문서:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content)  # Print each document"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
