{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19191,
     "status": "ok",
     "timestamp": 1739604164827,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "Ojlsc5Izydm6",
    "outputId": "b37d5856-80de-4fe8-a446-4457879247c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "PeY1QEffyjJp"
   },
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# !pip install python-dotenv openAI langchain_core langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvSfsBH6yjHD"
   },
   "outputs": [],
   "source": [
    "# 환경변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-KGYBfqCyjEY"
   },
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OSofIHmFyjBh"
   },
   "outputs": [],
   "source": [
    "# .env 파일에서 환경 변수 로드\n",
    "# load_dotenv(\"/content/.env\")\n",
    "load_dotenv(\"/.env\")\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 오픈AI 대규모 언어 모델 초기화\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 2309,
     "status": "ok",
     "timestamp": 1739604207596,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "abyMNsG5y47Q",
    "outputId": "af5be035-9113-4f28-bd94-3a1ff4dbc587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ' + name + ' 님!')\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"안녕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1739605813301,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "vc9C4EI3y44P",
    "outputId": "fca8128a-3a6b-4305-e753-4b083ccaacc3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'안녕하세요! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <오픈AI API를 사용하여 주제에 대한 간단한 설명 생성 파이프라인 구축>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import openai\n",
    "from typing import List\n",
    "\n",
    "# 기본 오픈AI 클라이언트 사용\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# \"안녀하세요!\" 메시지를 보내고 응답을 받음\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"안녕하세요!\"}]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 2471,
     "status": "ok",
     "timestamp": 1739605928730,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "_hkU3CPLlhAF",
    "outputId": "c24ee3ea-fec5-4442-fa37-e88a19961118"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\"더블딥\"은 경제학에서 사용하는 용어로, 경제가 두 번의 침체를 겪고 나서 회복하는 현상을 의미합니다. 첫 번째 침체 후에 일시적인 회복이 나타나지만, 이후에 다시 경제가 하락하는 경우를 말합니다. 이 현상은 일반적으로 경기 순환의 긴축적인 패턴을 나타내며, 경제 정책이나 시장의 신뢰도 등에 따라 발생할 수 있습니다. 더블딥은 투자자와 정책 입안자들에게 중요한 신호로 작용하며, 경제의 전반적인 건강 상태를 평가하는 데 도움을 줍니다.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요청에 사용할 프롬프트 템플릿 정의\n",
    "prompt_template = \"주제 {topic}에 대해 짧은 설명을 해주세요\"\n",
    "\n",
    "# 메시지를 보내고 모델의 응답을 받는 함수\n",
    "def call_chat_model(messages: List[dict]) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 주어진 주제에 따라 설명을 요청하는 함수\n",
    "def invoke_chain(topic: str) -> str:\n",
    "    prompt_value = prompt_template.format(topic=topic)\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt_value}]\n",
    "    return call_chat_model(messages)\n",
    "\n",
    "# \"더블딥\" 주제로 설명 요청\n",
    "invoke_chain(\"더블딥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 1984,
     "status": "ok",
     "timestamp": 1739606003013,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "xAFx-KbVy41N",
    "outputId": "16f74d47-3fdc-49e9-925d-53e97d2183c8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\"더블딥(Double Dip)\"은 경제 분야에서 주로 사용되는 용어로, 경기 침체가 일단 끝난 뒤 경제가 다시 회복되는 듯하다가 또 다시 침체로 접어드는 현상을 말합니다. 즉, 경제 성장률이 음수로 돌아섰다가 잠시 플러스로 전환된 이후 다시 음수로 떨어지는 두 번의 침체가 연속적으로 발생하는 것을 지칭합니다. 이는 소비 감소, 투자 부진, 외부 충격 등 여러 요인에 의해 발생할 수 있으며, 정책 결정자들에게 도전 과제가 될 수 있습니다.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <랭체인을 사용하여 주제에 대한 간단한 설명 생성 파이프라인 구축>\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "# 미스트랄AI 모델을 사용할 경우 주석 해제\n",
    "# from langchain_mistralai.chat_models import ChatMistralAI\n",
    "\n",
    "# 주어진 주제에 대해 짧은 설명을 요청하는 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"주제 {topic}에 대해 짧은 설명을 해주세요\"\n",
    ")\n",
    "\n",
    "# 출력 파서를 문자열로 설정\n",
    "output_parser = StrOutputParser()\n",
    "# 오픈AI의 gpt-4o 모델을 사용하여 채팅 모델 설정\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "# 미스트랄AI 모델을 사용할 경우 주석 해제\n",
    "# model = ChatMistralAI()\n",
    "\n",
    "# 파이프라인 설정: 주제를 받아 프롬프트를 생성하고, 모델을 통해 응답을 생성한 후 문자열로 파싱\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()}  # 입력 받은 주제를 그대로 통과시킴\n",
    "    | prompt                         # 프롬프트 템플릿을 적용\n",
    "    | model                          # 모델을 사용해 응답 생성\n",
    "    | output_parser                  # 응답을 문자열로 파싱\n",
    ")\n",
    "\n",
    "# \"더블딥\" 주제로 설명 요청\n",
    "chain.invoke(\"더블딥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDpMsEpXfJ1H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5MTD4DmvGL00Fy3VMJ6Hu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
