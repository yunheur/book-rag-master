{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3891,
     "status": "ok",
     "timestamp": 1741004880874,
     "user": {
      "displayName": "ì¡°ê²½ì•„",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "Ojlsc5Izydm6",
    "outputId": "c0adfdc2-168d-4ca7-aa69-f50e916a1f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "PeY1QEffyjJp"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip install python-dotenv langchain_openai langchain-chroma pypdf langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvSfsBH6yjHD"
   },
   "outputs": [],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KGYBfqCyjEY"
   },
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(\"/content/.env\")\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6GqDTFCaldW"
   },
   "outputs": [],
   "source": [
    "# <2024 ë¶€ë™ì‚° ë³´ê³ ì„œ RAG ì±—ë´‡>\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20215,
     "status": "ok",
     "timestamp": 1741001020404,
     "user": {
      "displayName": "ì¡°ê²½ì•„",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "567kMYTY_RK7",
    "outputId": "cc7a009f-8955-4842-a8b3-1c5061d8f4e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶„í• ëœ ì²­í¬ì˜ ìˆ˜: 135\n"
     ]
    }
   ],
   "source": [
    "# PDF ë¬¸ì„œ ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¶„í• \n",
    "loader = PyPDFLoader(\"/content/drive/MyDrive/langchain-tutorial/Ch02. RAG/Data/2024_KB_ë¶€ë™ì‚°_ë³´ê³ ì„œ_ìµœì¢….pdf\")\n",
    "documents = loader.load()  # ë¬¸ì„œ ë¡œë“œ\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í•  ì„¤ì •: ì²­í¬ í¬ê¸°ì™€ ê²¹ì¹¨ ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# ë¶„í• ëœ ì²­í¬ ìˆ˜\n",
    "print('ë¶„í• ëœ ì²­í¬ì˜ ìˆ˜:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxnoi4tDYJWg"
   },
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ìƒì„± ë° Chroma ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥\n",
    "embedding_function = OpenAIEmbeddings()  # ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "\n",
    "persist_directory = \"/content/drive/MyDrive/langchain-tutorial/Ch02. RAG/directory/chroma\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=persist_directory  # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²½ë¡œ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741001027452,
     "user": {
      "displayName": "ì¡°ê²½ì•„",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "CVX9CSgMARiy",
    "outputId": "86c91e0b-46f6-4cbe-d068-6d412b3a86c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì˜ ìˆ˜: 411\n"
     ]
    }
   ],
   "source": [
    "print('ë¬¸ì„œì˜ ìˆ˜:', vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHVOBLLscEVy"
   },
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ ë° ì¬ì •ë ¬\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})  # ê´€ë ¨ ë¬¸ì„œ ìƒìœ„ 3ê°œ ê²€ìƒ‰ ì„¤ì •\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •: ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•œ í…œí”Œë¦¿\n",
    "template = \"\"\"ë‹¹ì‹ ì€ KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì»¨í…ìŠ¤íŠ¸: {context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")  # í…œí”Œë¦¿ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)  # AI ëª¨ë¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1741001027684,
     "user": {
      "displayName": "ì¡°ê²½ì•„",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "n9peiaywSN7B",
    "outputId": "6af407fc-3fb1-4480-8d07-555bcd2c7cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: ë‹¹ì‹ ì€ KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "ì»¨í…ìŠ¤íŠ¸: ì»¨í…ìŠ¤íŠ¸ ì˜ˆì‹œ\n",
      "\n",
      "Human: ëŒ€í™” ê¸°ë¡ ì˜ˆì‹œ1\n",
      "Human: ëŒ€í™” ê¸°ë¡ ì˜ˆì‹œ2\n",
      "Human: ì§ˆë¬¸ ì˜ˆì‹œ\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(context=\"ì»¨í…ìŠ¤íŠ¸ ì˜ˆì‹œ\", chat_history=[\"ëŒ€í™” ê¸°ë¡ ì˜ˆì‹œ1\", \"ëŒ€í™” ê¸°ë¡ ì˜ˆì‹œ2\"], question=\"ì§ˆë¬¸ ì˜ˆì‹œ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z891npm-XOJE"
   },
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ í˜•ì‹ ë³€í™˜ í•¨ìˆ˜ ì •ì˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)  # ë¬¸ì„œ ë‚´ìš©ì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQvLvIB9Or7L"
   },
   "outputs": [],
   "source": [
    "# ì²´ì¸ êµ¬ì„±: ê²€ìƒ‰í•œ ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ì— ì—°ê²°í•˜ê³  ëª¨ë¸ì„ í†µí•´ ì‘ë‹µ ìƒì„±\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=lambda x: format_docs(retriever.invoke(x[\"question\"]))\n",
    "    )  # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì—°ê²°í•˜ì—¬ ì „ë‹¬\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()  # ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM2nx8PVVQ-j"
   },
   "outputs": [],
   "source": [
    "# ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "chat_history = ChatMessageHistory()\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,  # ì„¸ì…˜ IDë³„ ëŒ€í™” ê¸°ë¡ ìƒì„±\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6267,
     "status": "ok",
     "timestamp": 1741001033972,
     "user": {
      "displayName": "ì¡°ê²½ì•„",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "ISuCWtWMVQ7y",
    "outputId": "a881e418-febb-457d-d094-a8c50f651fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì±—ë´‡ì…ë‹ˆë‹¤. ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥)\n",
      "ì‚¬ìš©ì: quit\n"
     ]
    }
   ],
   "source": [
    "# ì±—ë´‡ ì‹¤í–‰ í•¨ìˆ˜ ì •ì˜\n",
    "def chat_with_bot():\n",
    "    session_id = \"user_session\"\n",
    "    print(\"KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì±—ë´‡ì…ë‹ˆë‹¤. ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥)\")\n",
    "    while True:\n",
    "        user_input = input(\"ì‚¬ìš©ì: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        response = chain_with_memory.invoke(\n",
    "            {\"question\": user_input},\n",
    "            {\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "\n",
    "        print(\"ì±—ë´‡:\", response)\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CYkPcYod5tAZ"
   },
   "outputs": [],
   "source": [
    "# <ìŠ¤íŠ¸ë¦¼ë¦¿ ì ìš©>\n",
    "\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "%%capture --no-stderr\n",
    "!pip install streamlit pyngrok\n",
    "\n",
    "# ngrok ì¸ì¦í‚¤ ì„¤ì •\n",
    "!ngrok config add-authtoken 2tnwXk5jQ5uWVBnwy3Ou8Mdmu8v_5eAtrJHxGZRiGGKqsqHsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCoW44bz764Z"
   },
   "outputs": [],
   "source": [
    "# app.py\n",
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(\"/content/.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# PDF ì²˜ë¦¬ í•¨ìˆ˜\n",
    "@st.cache_resource\n",
    "def process_pdf():\n",
    "    loader = PyPDFLoader(\"/content/drive/MyDrive/langchain-tutorial/Ch02. RAG/Data/2024_KB_ë¶€ë™ì‚°_ë³´ê³ ì„œ_ìµœì¢….pdf\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”\n",
    "@st.cache_resource\n",
    "def initialize_vectorstore():\n",
    "    chunks = process_pdf()\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "    return Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "# ì²´ì¸ ì´ˆê¸°í™”\n",
    "@st.cache_resource\n",
    "def initialize_chain():\n",
    "    vectorstore = initialize_vectorstore()\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    template = \"\"\"ë‹¹ì‹ ì€ KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "    ì»¨í…ìŠ¤íŠ¸: {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "    model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, openai_api_key=api_key)\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    base_chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=lambda x: format_docs(retriever.invoke(x[\"question\"]))\n",
    "        )\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return RunnableWithMessageHistory(\n",
    "        base_chain,\n",
    "        lambda session_id: ChatMessageHistory(),\n",
    "        input_messages_key=\"question\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "    )\n",
    "\n",
    "# Streamlit UI\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì±—ë´‡\", page_icon=\"ğŸ \")\n",
    "    st.title(\"ğŸ  KB ë¶€ë™ì‚° ë³´ê³ ì„œ AI ì–´ë“œë°”ì´ì €\")\n",
    "    st.caption(\"2024 KB ë¶€ë™ì‚° ë³´ê³ ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "    if prompt := st.chat_input(\"ë¶€ë™ì‚° ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\"):\n",
    "        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        # ì²´ì¸ ì´ˆê¸°í™”\n",
    "        chain = initialize_chain()\n",
    "\n",
    "        # AI ì‘ë‹µ ìƒì„±\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"ë‹µë³€ ìƒì„± ì¤‘...\"):\n",
    "                response = chain.invoke(\n",
    "                    {\"question\": prompt},\n",
    "                    {\"configurable\": {\"session_id\": \"streamlit_session\"}}\n",
    "                )\n",
    "                st.markdown(response)\n",
    "\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yb_DoR-_v5-o",
    "outputId": "378bf7ab-adbd-414c-8a08-140f22665798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•± ì ‘ì† URL: NgrokTunnel: \"https://d628-34-23-186-167.ngrok-free.app\" -> \"http://localhost:8501\"\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.23.186.167:8501\u001b[0m\n",
      "\u001b[0m\n",
      "/content/app.py:12: LangChainDeprecationWarning: Importing ChatMessageHistory from langchain.memory is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain.memory import ChatMessageHistory\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.chat_message_histories import ChatMessageHistory\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.memory import ChatMessageHistory\n",
      "/content/app.py:12: LangChainDeprecationWarning: Importing ChatMessageHistory from langchain.memory is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain.memory import ChatMessageHistory\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.chat_message_histories import ChatMessageHistory\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.memory import ChatMessageHistory\n",
      "/content/app.py:12: LangChainDeprecationWarning: Importing ChatMessageHistory from langchain.memory is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain.memory import ChatMessageHistory\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.chat_message_histories import ChatMessageHistory\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.memory import ChatMessageHistory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyngrok.process.ngrok:t=2025-03-03T13:41:11+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-5a6dbb55-2eea-44b3-9a82-4930899ee63a acceptErr=\"failed to accept connection: Listener closed\"\n",
      "WARNING:pyngrok.process.ngrok:t=2025-03-03T13:41:11+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-5a6dbb55-2eea-44b3-9a82-4930899ee63a err=\"failed to start tunnel: session closed\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  Stopping...\u001b[0m\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# í„°ë„ë§ ë° ì‹¤í–‰\n",
    "from pyngrok import ngrok\n",
    "\n",
    "public_url = ngrok.connect(8501)  # Streamlit ê¸°ë³¸ í¬íŠ¸\n",
    "print(\"ì•± ì ‘ì† URL:\", public_url)\n",
    "!streamlit run /content/app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RL2sLCHnvc2I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAxmEMI5LsnMrs7PUV2V6o",
   "provenance": [
    {
     "file_id": "1uyUNS30ebKj-Z2y9LfynVxat8Z-kGi4j",
     "timestamp": 1730783748682
    },
    {
     "file_id": "121A8jqwXbjJbUfwI0WuV53th7o0frtkK",
     "timestamp": 1730646342102
    },
    {
     "file_id": "1pdlCEHwvXT4Ljv9VGBciaemVHcBIiyMn",
     "timestamp": 1730563801037
    },
    {
     "file_id": "17pNawQlJCc7SQHqPznYT2QVIwvB4kjzI",
     "timestamp": 1729507273500
    },
    {
     "file_id": "1hYMuG0nH6xN6PV1yYXHF5rojjQIqhmi0",
     "timestamp": 1729491300245
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
