{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3891,
     "status": "ok",
     "timestamp": 1741004880874,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "Ojlsc5Izydm6",
    "outputId": "c0adfdc2-168d-4ca7-aa69-f50e916a1f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "PeY1QEffyjJp"
   },
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# !pip install python-dotenv langchain_openai langchain-chroma pypdf langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvSfsBH6yjHD"
   },
   "outputs": [],
   "source": [
    "# 환경변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-KGYBfqCyjEY"
   },
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m6GqDTFCaldW"
   },
   "outputs": [],
   "source": [
    "# <2024 부동산 보고서 RAG 챗봇>\n",
    "# 라이브러리 불러오기\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20215,
     "status": "ok",
     "timestamp": 1741001020404,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "567kMYTY_RK7",
    "outputId": "cc7a009f-8955-4842-a8b3-1c5061d8f4e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수: 135\n"
     ]
    }
   ],
   "source": [
    "# PDF 문서 로드 및 텍스트 분할\n",
    "# loader = PyPDFLoader(\"/content/drive/MyDrive/langchain-tutorial/Ch02. RAG/Data/2024_KB_부동산_보고서_최종.pdf\")\n",
    "loader = PyPDFLoader(\"./Data/2024_KB_부동산_보고서_최종.pdf\")\n",
    "documents = loader.load()  # 문서 로드\n",
    "\n",
    "# 텍스트 분할 설정: 청크 크기와 겹침 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 분할된 청크 수\n",
    "print('분할된 청크의 수:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mxnoi4tDYJWg"
   },
   "outputs": [],
   "source": [
    "# 임베딩 생성 및 Chroma 데이터베이스 저장\n",
    "embedding_function = OpenAIEmbeddings()  # 임베딩 모델 설정\n",
    "\n",
    "# persist_directory = \"/content/drive/MyDrive/langchain-tutorial/Ch02. RAG/directory/chroma\"\n",
    "persist_directory = \"./directory/chroma\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=persist_directory  # 데이터베이스 저장 경로\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741001027452,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "CVX9CSgMARiy",
    "outputId": "86c91e0b-46f6-4cbe-d068-6d412b3a86c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 135\n"
     ]
    }
   ],
   "source": [
    "print('문서의 수:', vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PHVOBLLscEVy"
   },
   "outputs": [],
   "source": [
    "# 검색 및 재정렬\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})  # 관련 문서 상위 3개 검색 설정\n",
    "\n",
    "# 프롬프트 템플릿 설정: 사용자 질문에 대한 답변을 생성하기 위한 템플릿\n",
    "template = \"\"\"당신은 KB 부동산 보고서 전문가입니다. 다음 정보를 바탕으로 사용자의 질문에 답변해주세요.\n",
    "\n",
    "컨텍스트: {context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")  # 템플릿 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)  # AI 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1741001027684,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "n9peiaywSN7B",
    "outputId": "6af407fc-3fb1-4480-8d07-555bcd2c7cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 당신은 KB 부동산 보고서 전문가입니다. 다음 정보를 바탕으로 사용자의 질문에 답변해주세요.\n",
      "\n",
      "컨텍스트: 컨텍스트 예시\n",
      "\n",
      "Human: 대화 기록 예시1\n",
      "Human: 대화 기록 예시2\n",
      "Human: 질문 예시\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(context=\"컨텍스트 예시\", chat_history=[\"대화 기록 예시1\", \"대화 기록 예시2\"], question=\"질문 예시\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z891npm-XOJE"
   },
   "outputs": [],
   "source": [
    "# 문서 형식 변환 함수 정의\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)  # 문서 내용을 줄바꿈으로 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kQvLvIB9Or7L"
   },
   "outputs": [],
   "source": [
    "# 체인 구성: 검색한 문서를 프롬프트에 연결하고 모델을 통해 응답 생성\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=lambda x: format_docs(retriever.invoke(x[\"question\"]))\n",
    "    )  # 검색된 문서를 연결하여 전달\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()  # 결과를 문자열로 변환\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DM2nx8PVVQ-j"
   },
   "outputs": [],
   "source": [
    "# 대화 기록을 유지하기 위한 메모리 설정\n",
    "chat_history = ChatMessageHistory()\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,  # 세션 ID별 대화 기록 생성\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6267,
     "status": "ok",
     "timestamp": 1741001033972,
     "user": {
      "displayName": "조경아",
      "userId": "05652149574770065967"
     },
     "user_tz": -540
    },
    "id": "ISuCWtWMVQ7y",
    "outputId": "a881e418-febb-457d-d094-a8c50f651fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB 부동산 보고서 챗봇입니다. 질문해 주세요. (종료하려면 'quit' 입력)\n",
      "챗봇: 랭체인 챗봇을 만들기 위한 실습을 진행 중이시군요! 랭체인(LLM Chain)은 대규모 언어 모델을 활용하여 다양한 작업을 수행할 수 있는 프레임워크입니다. 챗봇을 만들기 위해서는 다음과 같은 단계가 필요합니다:\n",
      "\n",
      "1. **환경 설정**: Python과 필요한 라이브러리(예: LangChain, OpenAI API 등)를 설치합니다.\n",
      "\n",
      "2. **API 키 설정**: OpenAI와 같은 언어 모델 API의 키를 설정합니다.\n",
      "\n",
      "3. **기본 구조 설계**: 챗봇의 기본 구조를 설계합니다. 사용자 입력을 받고, 모델에 전달하여 응답을 생성하는 흐름을 만듭니다.\n",
      "\n",
      "4. **대화 흐름 정의**: 사용자의 질문에 대한 응답을 어떻게 처리할지 정의합니다. 예를 들어, 특정 주제에 대한 질문에 대해 미리 정의된 답변을 제공할 수 있습니다.\n",
      "\n",
      "5. **테스트 및 개선**: 챗봇을 테스트하고, 사용자 피드백을 바탕으로 개선합니다.\n",
      "\n",
      "6. **배포**: 챗봇을 웹사이트나 애플리케이션에 통합하여 사용자들이 사용할 수 있도록 배포합니다.\n",
      "\n",
      "구체적인 코드나 예제가 필요하시다면, 어떤 부분에 대해 더 알고 싶으신지 말씀해 주시면 도와드리겠습니다!\n",
      "챗봇: 사용자님께서 \"랭체인 챗못 만들기에 대해 실습중입니다\"라고 말씀하셨습니다. 랭체인 챗봇을 만들기 위한 실습을 진행 중이라고 하셨습니다. 추가로 궁금한 점이나 도움이 필요하신 부분이 있으시면 말씀해 주세요!\n",
      "챗봇: 2024 KB 부동산 보고서에 따르면, 수도권 주택시장은 전반적으로 침체 상태에 있으며, 특히 강남권과 같은 선호 지역에서는 상대적으로 강세를 보이고 있습니다. 다음은 수도권 주택 매매 전망에 대한 주요 내용입니다:\n",
      "\n",
      "1. **거래 회복의 어려움**: 높은 기준금리와 주택 매매가격, DSR(총부채상환비율) 규제 등으로 인해 매수자들의 구매 여력이 회복되지 않고 있습니다. 매도자와 매수자 간의 희망가격 차이가 여전히 존재하여 거래가 위축되고 있습니다.\n",
      "\n",
      "2. **정부 규제 완화**: 2023년 이후 정부의 다양한 규제 완화가 이루어졌으며, 이는 매도자들의 기대 심리를 높이고 있습니다. 재건축 규제 완화와 같은 호재가 지역별로 존재하지만, 전반적인 주택 경기 위축 요소도 여전히 존재합니다.\n",
      "\n",
      "3. **지역별 차별화**: 서울의 경우, 강남구와 서초구 등 선호 지역에서는 긍정적인 기대감이 유지되고 있으나, 마포구와 용산구 등에서는 매도자와 매수자 간의 간극이 여전히 크고, 실제 매수 가담 여부가 중요한 요소로 작용할 것입니다.\n",
      "\n",
      "4. **전세 시장과의 연관성**: 전세가격 하락이 매매시장에 미치는 영향도 고려해야 합니다. 대규모 단지의 입주가 예정되어 있는 지역에서는 전세가격 하락이 매매가격에 영향을 줄 수 있습니다.\n",
      "\n",
      "5. **전반적인 전망**: 하반기 이후 거래 침체 현상이 다소 완화될 가능성이 있으나, 전반적인 회복세는 제한적일 것으로 보입니다. 매도자와 매수자 간의 희망가격 격차 축소와 매수세 회복이 중요합니다.\n",
      "\n",
      "이러한 요소들을 종합적으로 고려할 때, 수도권 주택시장은 단기적으로는 어려운 상황이 지속될 것으로 예상됩니다. 추가적인 질문이나 특정 지역에 대한 정보가 필요하시면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 챗봇 실행 함수 정의\n",
    "def chat_with_bot():\n",
    "    session_id = \"user_session\"\n",
    "    print(\"KB 부동산 보고서 챗봇입니다. 질문해 주세요. (종료하려면 'quit' 입력)\")\n",
    "    while True:\n",
    "        user_input = input(\"사용자: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        response = chain_with_memory.invoke(\n",
    "            {\"question\": user_input},\n",
    "            {\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "\n",
    "        print(\"챗봇:\", response)\n",
    "\n",
    "# 메인 실행\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CYkPcYod5tAZ"
   },
   "outputs": [],
   "source": [
    "# <스트림릿 적용>\n",
    "\n",
    "# 라이브러리 설치\n",
    "# %%capture --no-stderr\n",
    "# !pip install streamlit pyngrok\n",
    "\n",
    "# ngrok 인증키 설정\n",
    "# !ngrok config add-authtoken 2tnwXk5jQ5uWVBnwy3Ou8Mdmu8v_5eAtrJHxGZRiGGKqsqHsh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "app.py 파일을 생성하고 아래 코드를 복사해서 붙여넣기\n",
    "```\n",
    "# 스트림릿앱 실행\n",
    "streamlit run app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCoW44bz764Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 12:41:48.455 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.455 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.529 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/maui/Repository/personal/books/book-rag-master/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-18 12:41:48.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.530 Session state does not function when running a script without `streamlit run`\n",
      "2025-05-18 12:41:48.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-18 12:41:48.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# PDF 처리 함수\n",
    "@st.cache_resource\n",
    "def process_pdf():\n",
    "    # loader = PyPDFLoader(\"/content/drive/MyDrive/langchain-tutorial/Ch02. RAG/Data/2024_KB_부동산_보고서_최종.pdf\")\n",
    "    loader = PyPDFLoader(\"./Data/2024_KB_부동산_보고서_최종.pdf\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# 벡터 스토어 초기화\n",
    "@st.cache_resource\n",
    "def initialize_vectorstore():\n",
    "    chunks = process_pdf()\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "    return Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "# 체인 초기화\n",
    "@st.cache_resource\n",
    "def initialize_chain():\n",
    "    vectorstore = initialize_vectorstore()\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    template = \"\"\"당신은 KB 부동산 보고서 전문가입니다. 다음 정보를 바탕으로 사용자의 질문에 답변해주세요.\n",
    "\n",
    "    컨텍스트: {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "    model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, openai_api_key=api_key)\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    base_chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=lambda x: format_docs(retriever.invoke(x[\"question\"]))\n",
    "        )\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return RunnableWithMessageHistory(\n",
    "        base_chain,\n",
    "        lambda session_id: ChatMessageHistory(),\n",
    "        input_messages_key=\"question\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "    )\n",
    "\n",
    "# Streamlit UI\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"KB 부동산 보고서 챗봇\", page_icon=\"🏠\")\n",
    "    st.title(\"🏠 KB 부동산 보고서 AI 어드바이저\")\n",
    "    st.caption(\"2024 KB 부동산 보고서 기반 질의응답 시스템\")\n",
    "\n",
    "    # 세션 상태 초기화\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    # 채팅 기록 표시\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "\n",
    "    # 사용자 입력 처리\n",
    "    if prompt := st.chat_input(\"부동산 관련 질문을 입력하세요\"):\n",
    "        # 사용자 메시지 표시\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        # 체인 초기화\n",
    "        chain = initialize_chain()\n",
    "\n",
    "        # AI 응답 생성\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"답변 생성 중...\"):\n",
    "                response = chain.invoke(\n",
    "                    {\"question\": prompt},\n",
    "                    {\"configurable\": {\"session_id\": \"streamlit_session\"}}\n",
    "                )\n",
    "                st.markdown(response)\n",
    "\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yb_DoR-_v5-o",
    "outputId": "378bf7ab-adbd-414c-8a08-140f22665798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앱 접속 URL: NgrokTunnel: \"https://d628-34-23-186-167.ngrok-free.app\" -> \"http://localhost:8501\"\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.23.186.167:8501\u001b[0m\n",
      "\u001b[0m\n",
      "/content/app.py:12: LangChainDeprecationWarning: Importing ChatMessageHistory from langchain.memory is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain.memory import ChatMessageHistory\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.chat_message_histories import ChatMessageHistory\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.memory import ChatMessageHistory\n",
      "/content/app.py:12: LangChainDeprecationWarning: Importing ChatMessageHistory from langchain.memory is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain.memory import ChatMessageHistory\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.chat_message_histories import ChatMessageHistory\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.memory import ChatMessageHistory\n",
      "/content/app.py:12: LangChainDeprecationWarning: Importing ChatMessageHistory from langchain.memory is deprecated. Please replace deprecated imports:\n",
      "\n",
      ">> from langchain.memory import ChatMessageHistory\n",
      "\n",
      "with new imports of:\n",
      "\n",
      ">> from langchain_community.chat_message_histories import ChatMessageHistory\n",
      "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
      "  from langchain.memory import ChatMessageHistory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyngrok.process.ngrok:t=2025-03-03T13:41:11+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-5a6dbb55-2eea-44b3-9a82-4930899ee63a acceptErr=\"failed to accept connection: Listener closed\"\n",
      "WARNING:pyngrok.process.ngrok:t=2025-03-03T13:41:11+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-5a6dbb55-2eea-44b3-9a82-4930899ee63a err=\"failed to start tunnel: session closed\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  Stopping...\u001b[0m\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 터널링 및 실행\n",
    "from pyngrok import ngrok\n",
    "\n",
    "public_url = ngrok.connect(8501)  # Streamlit 기본 포트\n",
    "print(\"앱 접속 URL:\", public_url)\n",
    "!streamlit run /content/app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RL2sLCHnvc2I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAxmEMI5LsnMrs7PUV2V6o",
   "provenance": [
    {
     "file_id": "1uyUNS30ebKj-Z2y9LfynVxat8Z-kGi4j",
     "timestamp": 1730783748682
    },
    {
     "file_id": "121A8jqwXbjJbUfwI0WuV53th7o0frtkK",
     "timestamp": 1730646342102
    },
    {
     "file_id": "1pdlCEHwvXT4Ljv9VGBciaemVHcBIiyMn",
     "timestamp": 1730563801037
    },
    {
     "file_id": "17pNawQlJCc7SQHqPznYT2QVIwvB4kjzI",
     "timestamp": 1729507273500
    },
    {
     "file_id": "1hYMuG0nH6xN6PV1yYXHF5rojjQIqhmi0",
     "timestamp": 1729491300245
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
